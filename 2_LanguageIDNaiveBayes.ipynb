{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "413e50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93553b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2837c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shreds each document and returns a list with the counts for each character\n",
    "Index 0 is characters 'a' count, Index 1 is characters 'b' count, etc:\n",
    "Index 26 is the count for an empty space\n",
    "\"\"\"\n",
    "def shred_data(doc_list):\n",
    "    p = [0] * 27\n",
    "    val = 97\n",
    "    \n",
    "    for file in doc_list:\n",
    "        with open (file,encoding='utf-8') as f:\n",
    "        # TODO: add your code here\n",
    "            for line in f:\n",
    "                for c in line:\n",
    "                    ascii_c = ord(c)  \n",
    "                    # for every character check if in range and increase count\n",
    "                    if ascii_c >= ord('a') and ascii_c <= ord('z'):\n",
    "                        p[ascii_c - val] += 1\n",
    "                    elif chr(ascii_c) == ' ':\n",
    "                        p[26] += 1\n",
    "                          \n",
    "\n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c3ba24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate prior probabilities for each label\n",
    "\n",
    "\"\"\"\n",
    "def calc_prior(N, train_count, smoothing):\n",
    "    priors = []\n",
    "    labels = ['e','s','j']\n",
    "    i = 0\n",
    "    for label in labels:\n",
    "        n = (train_count[i] + smoothing)/(N + 3 * smoothing)\n",
    "        \n",
    "        s = 'P(y = ' + label + ') = ' + str(n)\n",
    "        print(s)\n",
    "        priors.append(n)\n",
    "    \n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f29252df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the class conditional probabilities for each character\n",
    "\"\"\"\n",
    "def calc_likelihood(lang_vector, smoothing, N):\n",
    "    theta = [0] * 27\n",
    "    \n",
    "    for i in range(27):\n",
    "        theta[i] = (lang_vector[i] + 0.5)/(np.array(lang_vector).sum() + 0.5 * 27)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c60441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the likelihood of p(x|y)\n",
    "\"\"\"\n",
    "def calc_test_l(theta, bow):\n",
    "    x = 0\n",
    "    for i in range(27):\n",
    "        x = x + bow[i] * math.log(theta[i])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916206c",
   "metadata": {},
   "source": [
    "# 2.1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54b43824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y = e) = 0.3333333333333333\n",
      "P(y = s) = 0.3333333333333333\n",
      "P(y = j) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "train_count = [10,10,10] # list that includes training counts for e, s, j in that order\n",
    "priors = calc_prior(30, train_count , 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88da34",
   "metadata": {},
   "source": [
    "# 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1a3a5560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class conditional probability for english\n",
      "[0.0601685114819098, 0.011134974392863043, 0.021509995043779945, 0.021972575582355856, 0.1053692383941847, 0.018932760614571286, 0.017478936064761277, 0.047216256401784236, 0.055410540227986124, 0.001420783082768875, 0.0037336857756484387, 0.028977366595076822, 0.020518751032545846, 0.057921691723112505, 0.06446390219725756, 0.01675202378985627, 0.0005617049396993227, 0.053824549810011564, 0.06618205848339666, 0.08012555757475633, 0.026664463902197257, 0.009284652238559392, 0.015496448042293078, 0.001156451346439782, 0.013844374690236246, 0.0006277878737815959, 0.1792499586981662]\n"
     ]
    }
   ],
   "source": [
    "labels = ['e', 's', 'j']\n",
    "lang_dict = {} # stores bag of words for each label for all training data\n",
    "\n",
    "for label in labels:\n",
    "    file_list = []\n",
    "    for i in range(10):\n",
    "        file = \"languageID\" + \"/\" + label + str(i) + \".txt\"\n",
    "        file_list.append(file)\n",
    "    lang_dict[label] = shred_data(file_list)\n",
    "    \n",
    "N = 0\n",
    "for label in lang_dict:\n",
    "    N += np.array(lang_dict[label]).sum()\n",
    "    \n",
    "# get english conditional probabilty\n",
    "theta_e = calc_likelihood(lang_dict['e'], 0.5, N)\n",
    "print(\"Class conditional probability for english\")\n",
    "print(theta_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf312a4",
   "metadata": {},
   "source": [
    "# 2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "463205bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class conditional probability for japanese\n",
      "[0.1317656102589189, 0.010866906600510151, 0.005485866033054963, 0.01722631818022992, 0.06020475907613823, 0.003878542227191726, 0.014011670568503443, 0.03176211607673224, 0.09703343932352633, 0.0023411020650616725, 0.05740941332681086, 0.001432614696530277, 0.03979873510604843, 0.05671057688947902, 0.09116321324993885, 0.0008735455466648031, 0.00010482546559977637, 0.04280373178657535, 0.0421747789929767, 0.056990111464411755, 0.07061742199238269, 0.0002445927530661449, 0.01974212935462455, 3.4941821866592126e-05, 0.01415143785596981, 0.00772214263251686, 0.12344945665466997]\n",
      "Class conditional probability for spanish\n",
      "[0.10456045141993771, 0.008232863618143134, 0.03752582405722919, 0.039745922111559924, 0.1138108599796491, 0.00860287996053159, 0.0071844839813758445, 0.0045327001942585795, 0.049859702136844375, 0.006629459467793161, 0.0002775122567913416, 0.052943171656748174, 0.02580863988159477, 0.054176559464709693, 0.07249236841293824, 0.02426690512164287, 0.007677839104560451, 0.05929511886774999, 0.06577040485954797, 0.03561407295488884, 0.03370232185254849, 0.00588942678301625, 9.250408559711388e-05, 0.0024976103111220747, 0.007862847275754679, 0.0026826184823163022, 0.16826493170115014]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class conditional probability for japanese\")\n",
    "theta_j = calc_likelihood(lang_dict['j'], 0.5, N)\n",
    "print(theta_j)\n",
    "theta_s = calc_likelihood(lang_dict['s'], 0.5, N)\n",
    "print(\"Class conditional probability for spanish\")\n",
    "print(theta_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e1f75",
   "metadata": {},
   "source": [
    "# 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b06d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164, 32, 53, 57, 311, 55, 51, 140, 140, 3, 6, 85, 64, 139, 182, 53, 3, 141, 186, 225, 65, 31, 47, 4, 38, 2, 498]\n"
     ]
    }
   ],
   "source": [
    "file = \"languageID/e10.txt\"\n",
    "bow = shred_data([file])\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977c1a9",
   "metadata": {},
   "source": [
    "# 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0e5d57ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x|y = e)\n",
      "-7841.865447060635\n",
      "P(x|y = s)\n",
      "-8467.282044010557\n",
      "P(x|y = j)\n",
      "-8771.433079075032\n"
     ]
    }
   ],
   "source": [
    "# probabilities below are stored in the log space\n",
    "\n",
    "print(\"P(x|y = e)\")\n",
    "e_likelihood = calc_test_l(theta_e, bow)\n",
    "print(e_likelihood)\n",
    "print(\"P(x|y = s)\")\n",
    "s_likelihood = calc_test_l(theta_s, bow)\n",
    "print(s_likelihood)\n",
    "print(\"P(x|y = j)\")\n",
    "j_likelihood = calc_test_l(theta_j, bow)\n",
    "print(j_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd9cf3",
   "metadata": {},
   "source": [
    "# 2.6\n",
    "\n",
    "Since p(y = e|x) = -7842 is the largest value or probability in the log space, the predicted class label for this document is english which is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a1427d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y = e|x)\n",
      "-7842.964059349303\n",
      "P(y = s|x)\n",
      "-8468.380656299225\n",
      "P(y = j|x)\n",
      "-8772.5316913637\n"
     ]
    }
   ],
   "source": [
    "# P(y = e|x) = P(x|y=e) * P(e)\n",
    "# Since arithmetic is done in log space we add log(P(e)) to log(P(x|y=e))\n",
    "\n",
    "print(\"P(y = e|x)\")\n",
    "print(e_likelihood + np.log(priors[0]))\n",
    "print(\"P(y = s|x)\")\n",
    "print(s_likelihood + np.log(priors[1]))\n",
    "print(\"P(y = j|x)\")\n",
    "print(j_likelihood + np.log(priors[2]))\n",
    "\n",
    "# English is the predicted class label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7a4ad",
   "metadata": {},
   "source": [
    "# 2.7\n",
    "\n",
    "See confusion matrix in HW4 document. The Naive Bayes Classifier had 100% accuracy with no False labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f252f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True English:  10\n",
      "True Spanish:  10\n",
      "True Japanese:  10\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "TE = 0\n",
    "FSE = 0\n",
    "FJE = 0\n",
    "TS = 0\n",
    "FES = 0\n",
    "FJS = 0\n",
    "TJ = 0\n",
    "FEJ = 0\n",
    "FSJ = 0\n",
    "\n",
    "label = \"e\"\n",
    "\n",
    "for i in range(10):\n",
    "    file = \"languageID\" + \"/\" + label + str(i+10) + \".txt\"\n",
    "    bow = shred_data([file])\n",
    "    e_likelihood = calc_test_l(theta_e, bow)\n",
    "    s_likelihood = calc_test_l(theta_s, bow)\n",
    "    j_likelihood = calc_test_l(theta_j, bow)\n",
    "     \n",
    "    \n",
    "    e_prob = e_likelihood + np.log(priors[0])\n",
    "    s_prob = s_likelihood + np.log(priors[1])\n",
    "    j_prob = j_likelihood + np.log(priors[2])\n",
    "\n",
    "    if(e_prob > s_prob and e_prob > j_prob):\n",
    "        TE += 1\n",
    "    elif(s_prob > e_prob and s_rpob > j_prob):\n",
    "        FSE += 1\n",
    "    else:\n",
    "        FJE += 1\n",
    "\n",
    "label = \"s\"\n",
    "\n",
    "for i in range(10):\n",
    "    file = \"languageID\" + \"/\" + label + str(i+10) + \".txt\"\n",
    "    bow = shred_data([file])\n",
    "    e_likelihood = calc_test_l(theta_e, bow)\n",
    "    s_likelihood = calc_test_l(theta_s, bow)\n",
    "    j_likelihood = calc_test_l(theta_j, bow)\n",
    "        \n",
    "    e_prob = e_likelihood + np.log(priors[0])\n",
    "    s_prob = s_likelihood + np.log(priors[1])\n",
    "    j_prob = j_likelihood + np.log(priors[2])\n",
    "    \n",
    "\n",
    "    if(s_prob > e_prob and s_prob > j_prob):\n",
    "        TS += 1\n",
    "    elif(e_prob > s_prob and e_rpob > j_prob):\n",
    "        FES += 1\n",
    "    else:\n",
    "        FJS += 1\n",
    "\n",
    "label = \"j\"\n",
    "\n",
    "for i in range(10):\n",
    "    file = \"languageID\" + \"/\" + label + str(i+10) + \".txt\"\n",
    "    bow = shred_data([file])\n",
    "    e_likelihood = calc_test_l(theta_e, bow)\n",
    "    s_likelihood = calc_test_l(theta_s, bow)\n",
    "    j_likelihood = calc_test_l(theta_j, bow)\n",
    "        \n",
    "    e_prob = e_likelihood + np.log(priors[0])\n",
    "    s_prob = s_likelihood + np.log(priors[1])\n",
    "    j_prob = j_likelihood + np.log(priors[2])\n",
    "    \n",
    "   \n",
    "    if(j_prob > e_prob and j_prob > s_prob):\n",
    "        TJ += 1\n",
    "    elif(e_prob > s_prob and e_rpob > j_prob):\n",
    "        FEJ += 1\n",
    "    else:\n",
    "        FSJ += 1\n",
    "        \n",
    "print(\"True English: \", str(TE))\n",
    "print(\"True Spanish: \", str(TS))\n",
    "print(\"True Japanese: \", str(TJ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760b71f",
   "metadata": {},
   "source": [
    "# 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "473f4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shuffle every line and every character in every line of document\n",
    "See shuffle.txt for results\n",
    "\"\"\"\n",
    "def shuffle(doc):\n",
    "    with open (doc,encoding='utf-8') as f:\n",
    "        lines = f.readlines() \n",
    "        \n",
    "    random.shuffle(lines)\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        line = \"\".join(random.sample(line, len(line)))\n",
    "        new_lines.append(line)\n",
    "    with open('shuffle.txt', 'w') as f: \n",
    "        f.writelines(new_lines) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a7e03225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling\n",
    "test_doc = \"languageID/e10.txt\"\n",
    "shuffle(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "580b0b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x|y = e)\n",
      "-7841.865447060635\n",
      "P(x|y = s)\n",
      "-8467.282044010557\n",
      "P(x|y = j)\n",
      "-8771.433079075032\n",
      "English\n",
      "-7842.964059349303\n",
      "Spanish\n",
      "-8468.380656299225\n",
      "Japanese\n",
      "-8772.5316913637\n"
     ]
    }
   ],
   "source": [
    "bow = shred_data([\"shuffle.txt\"])\n",
    "print(\"P(x|y = e)\")\n",
    "e_likelihood = calc_test_l(theta_e, bow)\n",
    "print(e_likelihood)\n",
    "print(\"P(x|y = s)\")\n",
    "s_likelihood = calc_test_l(theta_s, bow)\n",
    "print(s_likelihood)\n",
    "print(\"P(x|y = j)\")\n",
    "j_likelihood = calc_test_l(theta_j, bow)\n",
    "print(j_likelihood)\n",
    "\n",
    "print(\"English\")\n",
    "print(e_likelihood + np.log(priors[0]))\n",
    "print(\"Spanish\")\n",
    "print(s_likelihood + np.log(priors[1]))\n",
    "print(\"Japanese\")\n",
    "print(j_likelihood + np.log(priors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3d01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
